{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    " \n",
    "DATA_DIR = \"./bbc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}\n"
     ]
    }
   ],
   "source": [
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\")\n",
    "# calculate count of each category\n",
    "labels, counts = np.unique(data.target, return_counts=True)\n",
    "# convert data.target_names to np array for fancy indexing\n",
    "labels_str = np.array(data.target_names)[labels]\n",
    "print(dict(zip(labels_str, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US budget deficit to reach $368bn\\n\\nThe US budget deficit is set to hit a worse-t',\n",
       " 'WMC says Xstrata bid is too low\\n\\nAustralian mining firm WMC Resources has said i',\n",
       " \"Roxy Music on Isle of Wight bill\\n\\nRoxy Music will appear at June's Isle of Wight\",\n",
       " \"Newcastle 2-1 Bolton\\n\\nKieron Dyer smashed home the winner to end Bolton's 10-gam\",\n",
       " 'Italy 8-38 Wales\\n\\nWales secured their first away win in the RBS Six Nations for ',\n",
       " 'Newry to fight cup exit in courts\\n\\nNewry City are expected to discuss legal aven',\n",
       " 'Strong demand triggers oil rally\\n\\nCrude oil prices surged back above the $47 a b',\n",
       " 'Be careful how you code\\n\\nA new European directive could put software writers at ',\n",
       " 'Worldcom director ends evidence\\n\\nThe former chief financial officer at US teleco',\n",
       " \"Ministers deny care sums 'wrong'\\n\\nMinisters have insisted they are committed to \"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)\n",
    "list(t[:80] for t in X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=1000, decode_error=\"ignore\")\n",
    "vectorizer.fit(X_train)\n",
    "X_train_vectorized = vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using cross_val_score function, we’ll train the each model two times and record their mean accuracy. We’ll choose the highest performing model and train it and then evaluate it in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('svc_tfidf', 0.974220623501199), ('sgd_tfidf', 0.9592326139088729), ('svc', 0.9574340527577938), ('sgd', 0.9544364508393286)]\n"
     ]
    }
   ],
   "source": [
    "# start with the classic\n",
    "# with either pure counts or tfidf features\n",
    "sgd = Pipeline([\n",
    "        (\"count vectorizer\", CountVectorizer(stop_words=\"english\", max_features=3000)),\n",
    "        (\"sgd\", SGDClassifier(loss=\"modified_huber\"))\n",
    "    ])\n",
    "sgd_tfidf = Pipeline([\n",
    "        (\"tfidf_vectorizer\", TfidfVectorizer(stop_words=\"english\", max_features=3000)),\n",
    "        (\"sgd\", SGDClassifier(loss=\"modified_huber\"))\n",
    "    ])\n",
    " \n",
    "svc = Pipeline([\n",
    "        (\"count_vectorizer\", CountVectorizer(stop_words=\"english\", max_features=3000)),\n",
    "        (\"linear svc\", SVC(kernel=\"linear\"))\n",
    "    ])\n",
    "svc_tfidf = Pipeline([\n",
    "        (\"tfidf_vectorizer\", TfidfVectorizer(stop_words=\"english\", max_features=3000)),\n",
    "        (\"linear svc\", SVC(kernel=\"linear\"))\n",
    "    ])\n",
    "   \n",
    "all_models = [\n",
    "    (\"sgd\", sgd),\n",
    "    (\"sgd_tfidf\", sgd_tfidf),\n",
    "    (\"svc\", svc),\n",
    "    (\"svc_tfidf\", svc_tfidf),\n",
    "    ]\n",
    " \n",
    "unsorted_scores = [(name, cross_val_score(model, X_train, y_train, cv=2).mean()) for name, model in all_models]\n",
    "scores = sorted(unsorted_scores, key=lambda x: -x[1])\n",
    "print(scores)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Support Vector Machine with tf-idf features scored the highest accuracy of 97%. Lets train it and evaluate it in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748653500897666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       131\n",
      "           1       0.96      0.99      0.97        92\n",
      "           2       0.96      0.96      0.96       102\n",
      "           3       0.99      0.99      0.99       137\n",
      "           4       0.97      0.99      0.98        95\n",
      "\n",
      "    accuracy                           0.97       557\n",
      "   macro avg       0.97      0.98      0.97       557\n",
      "weighted avg       0.98      0.97      0.97       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = svc_tfidf\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('CV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60f6a9d4975695fc50618db0434ce57bd2e0dc030e1fbbf9fc29f4fd0ddc6562"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
